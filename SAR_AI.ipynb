{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OVKdsXrppj04JCrswCVpJW1hK3Dkqi14",
      "authorship_tag": "ABX9TyM9iCC5XGzOmDSb9UnIrwWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/8an-akr/SAR_AI/blob/main/SAR_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gitpython\n",
        "!pip install wget\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t14OjK-kjLEl",
        "outputId": "92a5b62f-a146-47e5-fb0a-60c38a4a4323"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=d455dc9c25417f019f74263be99af5af211ce2ecf122d72d32e519d90824ea84\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.94-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.94-py3-none-any.whl (949 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.94 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# Prompt for GitHub Token securely\n",
        "print(\"IMPORTANT: Do not share your GitHub token publicly!\")\n",
        "GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "GITHUB_REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/8an-akr/SAR_AI.git\"\n",
        "\n",
        "# Configure Git to use the token securely\n",
        "!git config --global user.email {userdata.get('MAIL')}\n",
        "!git config --global user.name \"8an-akr\"\n",
        "!git config --global credential.helper store\n",
        "!git config --global http.postBuffer 524288000\n",
        "!rm -rf /root/.git-credentials\n",
        "with open('/root/.git-credentials', 'w') as f:\n",
        "    f.write(f\"https://{GITHUB_TOKEN}:x-oauth-basic@github.com\\n\")\n",
        "!git config --global pull.rebase false\n",
        "\n",
        "print(\"Git configuration completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiE0G2GGrle5",
        "outputId": "89361d9d-2916-4cbb-b209-8f62ec2c9808"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: Do not share your GitHub token publicly!\n",
            "Git configuration completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Environment Setup\n",
        "\n",
        "import os\n",
        "from google.colab import auth\n",
        "import git\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw\n",
        "import subprocess\n",
        "import yaml\n"
      ],
      "metadata": {
        "id": "u7eQTMlilssd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HkOOGl3hKu6",
        "outputId": "d62bfe13-cde8-4bc6-9eb0-4ba48ee8fe23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Cloning into '/content/SAR_AI'...\n",
            "remote: Enumerating objects: 45562, done.\u001b[K\n",
            "remote: Counting objects: 100% (639/639), done.\u001b[K\n",
            "remote: Compressing objects: 100% (629/629), done.\u001b[K\n",
            "remote: Total 45562 (delta 19), reused 625 (delta 10), pack-reused 44923 (from 2)\u001b[K\n",
            "Receiving objects: 100% (45562/45562), 2.94 GiB | 27.61 MiB/s, done.\n",
            "Resolving deltas: 100% (1454/1454), done.\n",
            "Updating files: 100% (42072/42072), done.\n",
            "Repository is ready.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# GitHub repository URL and directory\n",
        "GITHUB_REPO_URL = 'https://github.com/8an-akr/SAR_AI.git'\n",
        "REPO_DIR = '/content/SAR_AI'\n",
        "\n",
        "import getpass\n",
        "\n",
        "# Clone or update the repository\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print('Cloning repository...')\n",
        "    !git clone {GITHUB_REPO_URL} {REPO_DIR}\n",
        "else:\n",
        "    print('Pulling latest updates...')\n",
        "    try:\n",
        "        # Check if main branch exists using GitPython\n",
        "        repo = git.Repo(REPO_DIR) # If you use this line, then import git\n",
        "        if 'main' not in repo.heads:\n",
        "            print(\"Initializing new branch 'main'...\")\n",
        "            # Create and checkout main branch\n",
        "            repo.git.checkout('-b', 'main')\n",
        "            # Create README.md\n",
        "            with open(os.path.join(REPO_DIR, 'README.md'), 'w') as f:\n",
        "                f.write(\"# SAR AI Project\")\n",
        "            # Add, commit, and push\n",
        "            repo.git.add('README.md')\n",
        "            repo.git.commit('-m', 'Initial commit with README')\n",
        "            repo.git.push('-u', 'origin', 'main')\n",
        "        else:\n",
        "            # Pull latest changes from main branch\n",
        "            repo.git.pull('origin', 'main')\n",
        "    except git.exc.GitCommandError as e:\n",
        "        print(f\"Error during Git operations: {e}\")\n",
        "\n",
        "print('Repository is ready.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Handling\n",
        "\n",
        "# Define paths for MSTAR and Sentinel12 datasets\n",
        "mstar_path = os.path.join(REPO_DIR, 'mstar')\n",
        "background_path = os.path.join(REPO_DIR, 'sentinel12')\n",
        "\n",
        "# Verify the existence of datasets\n",
        "if not os.path.exists(mstar_path):\n",
        "    print('Error: MSTAR dataset not found in the GitHub repository.')\n",
        "if not os.path.exists(background_path):\n",
        "    print('Error: Sentinel12 dataset not found in the GitHub repository.')\n",
        "\n",
        "print('Data verification complete!')\n",
        "\n",
        "# Prepare directories for synthetic images\n",
        "synthetic_image_dir = os.path.join(REPO_DIR, 'synthetic_images')\n",
        "os.makedirs(synthetic_image_dir, exist_ok=True)\n",
        "\n",
        "print('Synthetic image directory prepared!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da-r0dVThcI2",
        "outputId": "f7f26139-4eb5-4c0f-a708-85c013f13d09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data verification complete!\n",
            "Synthetic image directory prepared!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVfLR3-0ycjq",
        "outputId": "15c981bf-09cc-426c-e856-699d9c804655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Set up paths for training and validation directories\n",
        "train_dir = os.path.join(synthetic_image_dir, 'train')\n",
        "val_dir = os.path.join(synthetic_image_dir, 'val')\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Split ratio for training and validation\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Terrain classes\n",
        "terrain_classes = ['agri', 'barrenland', 'grassland', 'urban']\n",
        "vehicle_classes = ['2S1', 'BRDM_2', 'BTR_60', 'D7', 'SLICY', 'T62', 'ZIL131', 'ZSU_23_4']\n",
        "all_classes = terrain_classes + vehicle_classes  # Combine terrain and vehicle classes\n",
        "class_to_id = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "def generate_synthetic_image(image_index, background_size=(512, 512), num_objects=(3, 6)):\n",
        "    terrain_folders = ['agri', 'barrenland', 'grassland', 'urban']\n",
        "    selected_terrain = random.choice(terrain_folders)\n",
        "    terrain_type = selected_terrain\n",
        "    s_folder = 's1'\n",
        "    terrain_path = os.path.join(background_path, selected_terrain, s_folder)\n",
        "    background_files = os.listdir(terrain_path)\n",
        "    background_file = random.choice([f for f in background_files if f.lower().endswith(('.jpg', '.png'))])\n",
        "    canvas = Image.open(os.path.join(terrain_path, background_file)).convert('L')\n",
        "\n",
        "    # Ensure that the size is correctly handled as a tuple\n",
        "    if not isinstance(background_size, tuple):\n",
        "        background_size = (background_size, background_size)\n",
        "\n",
        "    canvas = canvas.resize(background_size)\n",
        "\n",
        "    label_lines = []\n",
        "\n",
        "    # Add terrain classification as a separate annotation (covering the entire image)\n",
        "    x_center, y_center = 0.5, 0.5  # Center of the image\n",
        "    w_norm, h_norm = 1.0, 1.0  # Full image coverage\n",
        "    terrain_label = f\"{class_to_id[terrain_type]} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\"\n",
        "    label_lines.append(terrain_label)\n",
        "\n",
        "    # Add vehicle detections\n",
        "    num_vehicles = random.randint(*num_objects)\n",
        "    for _ in range(num_vehicles):\n",
        "        cls = random.choice(vehicle_classes)\n",
        "        cls_id = class_to_id[cls]\n",
        "        img_files = os.listdir(os.path.join(mstar_path, cls))\n",
        "        img_file = random.choice([f for f in img_files if f.lower().endswith('.jpg')])\n",
        "        obj_img = Image.open(os.path.join(mstar_path, cls, img_file)).convert('L')\n",
        "\n",
        "        obj_img = obj_img.resize((random.randint(32, 64), random.randint(32, 64)))\n",
        "        w, h = obj_img.size\n",
        "        x = random.randint(0, background_size[0] - w)\n",
        "        y = random.randint(0, background_size[1] - h)\n",
        "        canvas.paste(obj_img, (x, y))\n",
        "\n",
        "        x_center = (x + w / 2) / background_size[0]\n",
        "        y_center = (y + h / 2) / background_size[1]\n",
        "        w_norm = w / background_size[0]\n",
        "        h_norm = h / background_size[1]\n",
        "        label_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
        "\n",
        "    # Decide whether to put in train or val\n",
        "    if random.random() < train_ratio:\n",
        "        img_dir = train_dir\n",
        "    else:\n",
        "        img_dir = val_dir\n",
        "\n",
        "    # Save the synthetic image and label\n",
        "    img_name = f\"synthetic_{image_index:04d}.jpg\"\n",
        "    label_name = img_name.replace('.jpg', '.txt')\n",
        "    canvas.save(os.path.join(img_dir, img_name))\n",
        "    with open(os.path.join(img_dir, label_name), 'w') as f:\n",
        "        f.write(\"\\n\".join(label_lines))\n",
        "\n",
        "    print(f\"Synthetic image saved: {img_name} in {img_dir}\")\n",
        "\n",
        "    return canvas, label_lines"
      ],
      "metadata": {
        "id": "-dl87yP5hfkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 1000 synthetic images in batches of 50\n",
        "batch_size = 50\n",
        "total_images = 300\n",
        "push_interval = 60  # Seconds between pushes\n",
        "\n",
        "print(\"Generating synthetic images...\")\n",
        "\n",
        "for batch_start in range(0, total_images, batch_size):\n",
        "    print(f\"Processing batch {batch_start + 1} to {batch_start + batch_size}...\")\n",
        "    for image_index in range(batch_start, batch_start + batch_size):\n",
        "        canvas, label_lines = generate_synthetic_image(image_index)  # Pass unique index to generate_synthetic_image\n",
        "\n",
        "    # Push the batch of images to GitHub\n",
        "    print(f\"Pushing batch {batch_start + 1} to {batch_start + batch_size} to GitHub...\")\n",
        "    try:\n",
        "        # Stage all new images and labels in the synthetic directory\n",
        "        add_all = subprocess.run(['git', 'add', synthetic_image_dir], check=False, cwd=REPO_DIR, capture_output=True, text=True)\n",
        "        if add_all.returncode != 0:\n",
        "            print(f\"Error adding files: {add_all.stderr}\")\n",
        "            continue\n",
        "\n",
        "        # Commit the changes\n",
        "        commit = subprocess.run(['git', 'commit', '-m', f'Add synthetic images batch {batch_start + 1} to {batch_start + batch_size}'], check=False, cwd=REPO_DIR, capture_output=True, text=True)\n",
        "        if commit.returncode != 0:\n",
        "            print(f\"Error committing changes: {commit.stderr}\")\n",
        "            continue\n",
        "\n",
        "        # Push to GitHub\n",
        "        push = subprocess.run(['git', 'push', 'origin', 'main'], check=False, cwd=REPO_DIR, capture_output=True, text=True)\n",
        "        if push.returncode != 0:\n",
        "            print(f\"Error pushing changes: {push.stderr}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Batch {batch_start + 1} to {batch_start + batch_size} successfully pushed to GitHub!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Exception during push: {str(e)}\")\n",
        "\n",
        "print(\"All synthetic images generated and pushed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6kHHwx6BVKr",
        "outputId": "1f09c2b4-0ba2-4872-f5ba-bbf2ef38db3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic images...\n",
            "Processing batch 1 to 50...\n",
            "Synthetic image saved: synthetic_0000.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0001.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0002.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0003.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0004.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0005.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0006.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0007.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0008.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0009.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0010.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0011.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0012.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0013.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0014.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0015.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0016.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0017.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0018.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0019.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0020.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0021.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0022.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0023.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0024.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0025.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0026.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0027.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0028.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0029.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0030.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0031.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0032.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0033.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0034.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0035.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0036.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0037.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0038.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0039.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0040.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0041.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0042.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0043.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0044.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0045.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0046.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0047.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0048.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0049.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Pushing batch 1 to 50 to GitHub...\n",
            "Batch 1 to 50 successfully pushed to GitHub!\n",
            "Processing batch 51 to 100...\n",
            "Synthetic image saved: synthetic_0050.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0051.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0052.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0053.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0054.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0055.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0056.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0057.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0058.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0059.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0060.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0061.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0062.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0063.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0064.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0065.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0066.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0067.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0068.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0069.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0070.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0071.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0072.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0073.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0074.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0075.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0076.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0077.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0078.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0079.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0080.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0081.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0082.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0083.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0084.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0085.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0086.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0087.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0088.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0089.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0090.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0091.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0092.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0093.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0094.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0095.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0096.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0097.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0098.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0099.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Pushing batch 51 to 100 to GitHub...\n",
            "Batch 51 to 100 successfully pushed to GitHub!\n",
            "Processing batch 101 to 150...\n",
            "Synthetic image saved: synthetic_0100.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0101.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0102.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0103.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0104.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0105.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0106.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0107.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0108.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0109.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0110.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0111.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0112.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0113.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0114.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0115.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0116.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0117.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0118.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0119.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0120.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0121.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0122.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0123.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0124.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0125.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0126.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0127.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0128.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0129.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0130.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0131.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0132.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0133.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0134.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0135.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0136.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0137.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0138.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0139.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0140.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0141.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0142.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0143.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0144.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0145.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0146.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0147.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0148.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0149.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Pushing batch 101 to 150 to GitHub...\n",
            "Batch 101 to 150 successfully pushed to GitHub!\n",
            "Processing batch 151 to 200...\n",
            "Synthetic image saved: synthetic_0150.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0151.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0152.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0153.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0154.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0155.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0156.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0157.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0158.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0159.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0160.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0161.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0162.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0163.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0164.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0165.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0166.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0167.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0168.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0169.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0170.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0171.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0172.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0173.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0174.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0175.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0176.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0177.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0178.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0179.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0180.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0181.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0182.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0183.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0184.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0185.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0186.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0187.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0188.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0189.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0190.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0191.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0192.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0193.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0194.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0195.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0196.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0197.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0198.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0199.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Pushing batch 151 to 200 to GitHub...\n",
            "Batch 151 to 200 successfully pushed to GitHub!\n",
            "Processing batch 201 to 250...\n",
            "Synthetic image saved: synthetic_0200.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0201.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0202.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0203.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0204.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0205.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0206.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0207.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0208.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0209.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0210.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0211.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0212.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0213.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0214.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0215.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0216.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0217.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0218.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0219.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0220.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0221.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0222.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0223.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0224.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0225.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0226.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0227.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0228.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0229.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0230.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0231.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0232.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0233.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0234.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0235.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0236.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0237.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0238.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0239.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0240.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0241.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0242.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0243.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0244.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0245.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0246.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0247.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0248.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0249.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Pushing batch 201 to 250 to GitHub...\n",
            "Batch 201 to 250 successfully pushed to GitHub!\n",
            "Processing batch 251 to 300...\n",
            "Synthetic image saved: synthetic_0250.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0251.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0252.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0253.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0254.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0255.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0256.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0257.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0258.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0259.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0260.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0261.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0262.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0263.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0264.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0265.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0266.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0267.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0268.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0269.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0270.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0271.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0272.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0273.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0274.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0275.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0276.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0277.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0278.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0279.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0280.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0281.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0282.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0283.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0284.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0285.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0286.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0287.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0288.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0289.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0290.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0291.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0292.jpg in /content/SAR_AI/synthetic_images/val\n",
            "Synthetic image saved: synthetic_0293.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0294.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0295.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0296.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0297.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0298.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Synthetic image saved: synthetic_0299.jpg in /content/SAR_AI/synthetic_images/train\n",
            "Pushing batch 251 to 300 to GitHub...\n",
            "Batch 251 to 300 successfully pushed to GitHub!\n",
            "All synthetic images generated and pushed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Define Vehicle and Terrain Classes\n",
        "vehicle_classes = ['2S1', 'BRDM_2', 'BTR_60', 'D7', 'SLICY', 'T62', 'ZIL131', 'ZSU_23_4']\n",
        "terrain_classes = ['agri', 'barrenland', 'grassland', 'urban']\n",
        "\n",
        "# Combine vehicle and terrain classes\n",
        "all_classes = vehicle_classes + terrain_classes\n",
        "\n",
        "# Create YOLOv8 data configuration file\n",
        "data_yaml = {\n",
        "    'train': os.path.join(synthetic_image_dir, 'train'),\n",
        "    'val': os.path.join(synthetic_image_dir, 'val'),\n",
        "    'nc': len(all_classes),\n",
        "    'names': all_classes\n",
        "}\n",
        "\n",
        "yaml_path = os.path.join(REPO_DIR, 'data.yaml')\n",
        "with open(yaml_path, 'w') as file:\n",
        "    yaml.dump(data_yaml, file)\n",
        "\n",
        "print(f\"YOLOv8 data configuration file saved at: {yaml_path}\")\n",
        "\n",
        "try:\n",
        "    # Stage the data.yaml file\n",
        "    add_all = subprocess.run(['git', 'add', yaml_path], check=False, cwd=REPO_DIR, capture_output=True, text=True)\n",
        "    if add_all.returncode != 0:\n",
        "        print(f\"Error adding files: {add_all.stderr}\")\n",
        "\n",
        "    # Commit the changes with a clear message\n",
        "    commit_message = 'Add YOLOv8 data configuration file with all classes'\n",
        "    commit = subprocess.run(['git', 'commit', '-m', commit_message], check=False, cwd=REPO_DIR, capture_output=True, text=True)\n",
        "    if \"nothing to commit\" in commit.stderr:\n",
        "        print(\"Nothing to commit, working tree clean.\")\n",
        "    elif commit.returncode != 0:\n",
        "        print(f\"Error committing changes: {commit.stderr}\")\n",
        "\n",
        "    # Push to GitHub\n",
        "    push = subprocess.run(['git', 'push', 'origin', 'main'], check=False, cwd=REPO_DIR, capture_output=True, text=True)\n",
        "    if push.returncode != 0:\n",
        "        print(f\"Error pushing changes: {push.stderr}\")\n",
        "    else:\n",
        "        print(f\"Data.yaml successfully pushed to GitHub!\")\n",
        "except Exception as e:\n",
        "    print(f\"Exception during push: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAJiyN6VBwWc",
        "outputId": "23effd80-e05a-4936-dcbd-4eb825bf280d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 data configuration file saved at: /content/SAR_AI/data.yaml\n",
            "Error committing changes: \n",
            "Data.yaml successfully pushed to GitHub!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: YOLOv8 Training\n",
        "synthetic_image_dir = yaml_path\n",
        "print('Training YOLOv8 model on synthetic data...')\n",
        "\n",
        "# Ensure the synthetic image directory is properly set\n",
        "if not os.path.exists(synthetic_image_dir):\n",
        "    print(f\"Error: Synthetic image directory '{synthetic_image_dir}' not found.\")\n",
        "else:\n",
        "    try:\n",
        "        # Initialize the YOLOv8 model\n",
        "        model = YOLO('yolov8n.pt')\n",
        "\n",
        "        # Check the directory contents to confirm data presence\n",
        "        print(f\"Directory contents of {synthetic_image_dir}:\")\n",
        "        for root, dirs, files in os.walk(synthetic_image_dir):\n",
        "            print(f\"{root}: {len(files)} files\")\n",
        "\n",
        "        # Train the model on synthetic images\n",
        "        results = model.train(\n",
        "            data=synthetic_image_dir,\n",
        "            epochs=50,\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            name=\"yolov8_sar\",\n",
        "            save=True,\n",
        "            project=os.path.join(REPO_DIR, \"runs/train\")\n",
        "        )\n",
        "\n",
        "        print('Training complete!')\n",
        "\n",
        "        # Save the trained model path\n",
        "        trained_model_path = os.path.join(REPO_DIR, \"runs/train/yolov8_sar/weights/best.pt\")\n",
        "        print(f'Trained model saved at: {trained_model_path}')\n",
        "\n",
        "        # Push the trained model to GitHub\n",
        "        print(\"Pushing trained model to GitHub...\")\n",
        "        try:\n",
        "            subprocess.run(['git', 'add', trained_model_path], check=True, cwd=REPO_DIR)\n",
        "            subprocess.run(['git', 'commit', '-m', 'Add trained YOLOv8 model'], check=True, cwd=REPO_DIR)\n",
        "            subprocess.run(['git', 'push', 'origin', 'main'], check=True, cwd=REPO_DIR)\n",
        "            print(\"Trained model successfully pushed to GitHub!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model push: {str(e)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyVuhRc0hi_N",
        "outputId": "b640d13c-c23f-425b-da35-62624a3cd8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training YOLOv8 model on synthetic data...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 108MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory contents of /content/SAR_AI/data.yaml:\n",
            "Ultralytics 8.3.94 🚀 Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/SAR_AI/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/SAR_AI/runs/train, name=yolov8_sar, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/SAR_AI/runs/train/yolov8_sar\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 16.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753652  ultralytics.nn.modules.head.Detect           [12, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,013,188 parameters, 3,013,172 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/SAR_AI/runs/train/yolov8_sar', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/SAR_AI/synthetic_images/train... 242 images, 0 backgrounds, 0 corrupt: 100%|██████████| 242/242 [00:00<00:00, 1467.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/SAR_AI/synthetic_images/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/SAR_AI/synthetic_images/val... 58 images, 0 backgrounds, 0 corrupt: 100%|██████████| 58/58 [00:00<00:00, 1665.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/SAR_AI/synthetic_images/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/SAR_AI/runs/train/yolov8_sar/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/SAR_AI/runs/train/yolov8_sar\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50         0G     0.9758      4.081      1.209         14        640: 100%|██████████| 16/16 [03:18<00:00, 12.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<00:00,  9.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331    0.00373      0.356      0.048     0.0275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50         0G     0.5203       3.24     0.9998         21        640: 100%|██████████| 16/16 [03:15<00:00, 12.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<00:00,  8.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331     0.0255      0.569     0.0714     0.0475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50         0G     0.4607      2.517     0.9429         19        640: 100%|██████████| 16/16 [03:13<00:00, 12.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<00:00,  8.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331     0.0514      0.964      0.219      0.182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50         0G      0.395      2.169     0.9069         30        640: 100%|██████████| 16/16 [03:15<00:00, 12.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331     0.0592      0.991      0.257      0.241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50         0G     0.3775      2.016     0.9019          9        640: 100%|██████████| 16/16 [03:16<00:00, 12.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.522      0.283      0.269      0.227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50         0G       0.38      1.888     0.8897         25        640: 100%|██████████| 16/16 [03:10<00:00, 11.94s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.454      0.492       0.37      0.325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50         0G     0.3479      1.782     0.8933         11        640: 100%|██████████| 16/16 [03:12<00:00, 12.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.261      0.616      0.421      0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50         0G     0.3223      1.632     0.8774         20        640: 100%|██████████| 16/16 [03:17<00:00, 12.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.283      0.611      0.453      0.428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50         0G      0.321      1.627     0.8725         11        640: 100%|██████████| 16/16 [03:10<00:00, 11.89s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<00:00,  8.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.275      0.698      0.429      0.414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50         0G     0.2932      1.497     0.8578         24        640: 100%|██████████| 16/16 [03:10<00:00, 11.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.301      0.739      0.545      0.523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50         0G     0.3002      1.469     0.8728         18        640: 100%|██████████| 16/16 [03:13<00:00, 12.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.374      0.726      0.568       0.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50         0G     0.2831      1.425     0.8631         18        640: 100%|██████████| 16/16 [03:18<00:00, 12.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<00:00,  7.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.453      0.666      0.599       0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50         0G     0.2731      1.417      0.856         22        640: 100%|██████████| 16/16 [03:08<00:00, 11.81s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.439      0.694      0.587      0.572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50         0G     0.2725      1.364     0.8558         20        640: 100%|██████████| 16/16 [03:12<00:00, 12.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<00:00,  8.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331        0.8       0.47      0.573      0.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50         0G     0.2717      1.334     0.8504         27        640: 100%|██████████| 16/16 [03:13<00:00, 12.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         58        331      0.473      0.698      0.614      0.596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50         0G     0.2458      1.323     0.8617          7        640: 100%|██████████| 16/16 [03:12<00:00, 12.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: YOLOv8 Training\n",
        "synthetic_image_dir = yaml_path\n",
        "print('Training YOLOv8 model on synthetic data...')\n",
        "\n",
        "# Ensure the synthetic image directory is properly set\n",
        "if not os.path.exists(synthetic_image_dir):\n",
        "    print(f\"Error: Synthetic image directory '{synthetic_image_dir}' not found.\")\n",
        "else:\n",
        "    try:\n",
        "        # Resume training from the best checkpoint if it exists\n",
        "        trained_model_path = os.path.join(REPO_DIR, \"runs/train/yolov8_sar/weights/best.pt\")\n",
        "        if os.path.exists(trained_model_path):\n",
        "            print(f\"Resuming training from the best checkpoint: {trained_model_path}\")\n",
        "            model = YOLO(trained_model_path)\n",
        "        else:\n",
        "            print(\"No checkpoint found. Starting training from scratch.\")\n",
        "            model = YOLO('yolov8n.pt')\n",
        "\n",
        "        # Check the directory contents to confirm data presence\n",
        "        print(f\"Directory contents of {synthetic_image_dir}:\")\n",
        "        for root, dirs, files in os.walk(synthetic_image_dir):\n",
        "            print(f\"{root}: {len(files)} files\")\n",
        "\n",
        "        # Train the model on synthetic images\n",
        "        epochs_per_checkpoint = 5\n",
        "        total_epochs = 50\n",
        "\n",
        "        for start_epoch in range(0, total_epochs, epochs_per_checkpoint):\n",
        "            end_epoch = min(start_epoch + epochs_per_checkpoint, total_epochs)\n",
        "            print(f\"Training from epoch {start_epoch + 1} to {end_epoch}...\")\n",
        "\n",
        "            results = model.train(\n",
        "                data=synthetic_image_dir,\n",
        "                epochs=end_epoch,\n",
        "                imgsz=640,\n",
        "                batch=16,\n",
        "                name=\"yolov8_sar\",\n",
        "                save=True,\n",
        "                project=os.path.join(REPO_DIR, \"runs/train\"),\n",
        "                resume=True  # Continue training from the best checkpoint\n",
        "            )\n",
        "\n",
        "            print(f'Epochs {start_epoch + 1}-{end_epoch} complete!')\n",
        "\n",
        "            # Save the trained model path\n",
        "            trained_model_path = os.path.join(REPO_DIR, \"runs/train/yolov8_sar/weights/best.pt\")\n",
        "            print(f'Trained model saved at: {trained_model_path}')\n",
        "\n",
        "            # Push the trained model to GitHub\n",
        "            print(\"Pushing trained model to GitHub...\")\n",
        "            try:\n",
        "                subprocess.run(['git', 'add', trained_model_path], check=True, cwd=REPO_DIR)\n",
        "                subprocess.run(['git', 'commit', '-m', f'Checkpoint after {end_epoch} epochs'], check=True, cwd=REPO_DIR)\n",
        "                subprocess.run(['git', 'push', 'origin', 'main'], check=True, cwd=REPO_DIR)\n",
        "                print(\"Checkpoint successfully pushed to GitHub!\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error during model push: {str(e)}\")\n",
        "\n",
        "        print('Training complete!')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {str(e)}\")"
      ],
      "metadata": {
        "id": "KJQygkHMYpRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Inference and Visualization\n",
        "print('Running inference on test data...')\n",
        "\n",
        "# Directory to save inference results\n",
        "inference_dir = os.path.join(REPO_DIR, \"inference_results\")\n",
        "os.makedirs(inference_dir, exist_ok=True)\n",
        "\n",
        "# Run YOLOv8 inference\n",
        "try:\n",
        "    test_results = model.predict(source=synthetic_image_dir, save=True)\n",
        "    print('Inference complete!')\n",
        "except Exception as e:\n",
        "    print(f\"Error during inference: {str(e)}\")\n",
        "\n",
        "# Visualization function to display and save results with bounding boxes\n",
        "def visualize_and_save(image_path, results):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    for result in results:\n",
        "        x1, y1, x2, y2 = result['box']\n",
        "        label = result['label']\n",
        "        confidence = result['confidence']\n",
        "\n",
        "        # Draw bounding box\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
        "\n",
        "        # Draw label with confidence\n",
        "        label_text = f\"{label} ({confidence:.2f})\"\n",
        "        text_width, text_height = draw.textsize(label_text)\n",
        "        draw.rectangle([x1, y1 - text_height, x1 + text_width, y1], fill=\"red\")\n",
        "        draw.text((x1, y1 - text_height), label_text, fill=\"white\")\n",
        "\n",
        "    # Save the image to the inference results directory\n",
        "    save_path = os.path.join(inference_dir, os.path.basename(image_path))\n",
        "    image.save(save_path)\n",
        "    print(f\"Saved inference result: {save_path}\")\n",
        "\n",
        "    # Display the image\n",
        "    display(image)\n",
        "\n",
        "# Loop through the test results and visualize\n",
        "for result in test_results:\n",
        "    image_path = result.path\n",
        "    boxes = result.boxes.xyxy.cpu().numpy()\n",
        "    labels = result.boxes.cls.cpu().numpy()\n",
        "    confidences = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "    result_details = []\n",
        "    for box, label, confidence in zip(boxes, labels, confidences):\n",
        "        label_name = model.names[int(label)]\n",
        "        result_details.append({\n",
        "            \"box\": box.tolist(),\n",
        "            \"label\": label_name,\n",
        "            \"confidence\": confidence\n",
        "        })\n",
        "    visualize_and_save(image_path, result_details)\n",
        "\n",
        "# Push the inference results to GitHub\n",
        "print(\"Pushing inference results to GitHub...\")\n",
        "try:\n",
        "    subprocess.run(['git', 'add', inference_dir], check=True, cwd=REPO_DIR)\n",
        "    subprocess.run(['git', 'commit', '-m', 'Add YOLOv8 inference results'], check=True, cwd=REPO_DIR)\n",
        "    subprocess.run(['git', 'push', 'origin', 'main'], check=True, cwd=REPO_DIR)\n",
        "    print(\"Inference results successfully pushed to GitHub!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error pushing inference results: {str(e)}\")"
      ],
      "metadata": {
        "id": "CmqdH_z2hlpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "myDPLKL5AKk-",
        "outputId": "258978d6-1180-4f83-fc66-89792a0db483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    }
  ]
}